{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_keras_1.2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandvimal/deeplearning-experiments/blob/master/mnist_keras_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vePLDQZ9Jms9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Experiment 1.2 MNIST\n",
        "this experiment is iteration from deep learning with keras book chapter 1\n",
        "\n",
        "In this experiment we will use more epochs (250) as compared to 20 in last version. "
      ]
    },
    {
      "metadata": {
        "id": "W5wAcEf-Jdu1",
        "colab_type": "code",
        "outputId": "2952ea66-6aaf-428a-da29-bb2f58e31cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(1671)  # for reproducibility\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "C1d5p_zDJ3PW",
        "colab_type": "code",
        "outputId": "c3868f01-d0a7-46b8-c45f-ea611cd67c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "# network and training\n",
        "NB_EPOCH = 250         #more number of epochs this time\n",
        "#NB_EPOCH = 500\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of classes(digits)\n",
        "OPTIMIZER = SGD() \n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "DROPOUT = 0.3        # we will use dropout to make sure model doest overfit as no of epochs we are doing are large."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1XRSx_LVQPEP",
        "colab_type": "code",
        "outputId": "dd4e4321-47ed-4487-9c6b-0c6760d58c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# data: shuffled and split between train and test sets\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uekzj8jkQTtg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q3AgobPAQVoD",
        "colab_type": "code",
        "outputId": "600ba1f9-b7fe-4da0-e67a-cb3dd30eefa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# normalize \n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7PIPnDZfQcOY",
        "colab_type": "code",
        "outputId": "5a182393-988b-418f-d4bc-f4c4b9e06782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "# normalize \n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PCX5L6DFRMTK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to binary class matrices\n",
        "# one hot encoding\n",
        "Y_train = np_utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(Y_test, NB_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yabl_05FRPHs",
        "colab_type": "code",
        "outputId": "5299980b-5029-41aa-d203-320a1c7aeab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "cell_type": "code",
      "source": [
        "#model \n",
        "model =Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(NB_CLASSES)) #we only have 10 classes for classification\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4BInsiKETpzQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=OPTIMIZER,\n",
        "    metrics=['accuracy']    \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nvoa0-pPUdHW",
        "colab_type": "code",
        "outputId": "fea58e96-d229-4cae-f009-5c39bb3e36be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8504
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, \n",
        "    Y_train,               \n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=NB_EPOCH,\n",
        "    verbose = VERBOSE,\n",
        "    validation_split=VALIDATION_SPLIT\n",
        "    )\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/250\n",
            "48000/48000 [==============================] - 3s 58us/step - loss: 1.7404 - acc: 0.4538 - val_loss: 0.9292 - val_acc: 0.8123\n",
            "Epoch 2/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.9231 - acc: 0.7229 - val_loss: 0.5400 - val_acc: 0.8652\n",
            "Epoch 3/250\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.6935 - acc: 0.7879 - val_loss: 0.4298 - val_acc: 0.8883\n",
            "Epoch 4/250\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.5947 - acc: 0.8210 - val_loss: 0.3790 - val_acc: 0.8977\n",
            "Epoch 5/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.5347 - acc: 0.8393 - val_loss: 0.3456 - val_acc: 0.9040\n",
            "Epoch 6/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.4976 - acc: 0.8524 - val_loss: 0.3232 - val_acc: 0.9107\n",
            "Epoch 7/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.4616 - acc: 0.8628 - val_loss: 0.3048 - val_acc: 0.9127\n",
            "Epoch 8/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.4386 - acc: 0.8688 - val_loss: 0.2896 - val_acc: 0.9171\n",
            "Epoch 9/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.4181 - acc: 0.8761 - val_loss: 0.2776 - val_acc: 0.9198\n",
            "Epoch 10/250\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.3990 - acc: 0.8839 - val_loss: 0.2657 - val_acc: 0.9233\n",
            "Epoch 11/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.3819 - acc: 0.8876 - val_loss: 0.2552 - val_acc: 0.9257\n",
            "Epoch 12/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.3688 - acc: 0.8921 - val_loss: 0.2465 - val_acc: 0.9282\n",
            "Epoch 13/250\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.3571 - acc: 0.8943 - val_loss: 0.2388 - val_acc: 0.9301\n",
            "Epoch 14/250\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.3466 - acc: 0.8992 - val_loss: 0.2319 - val_acc: 0.9322\n",
            "Epoch 15/250\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.3358 - acc: 0.9014 - val_loss: 0.2261 - val_acc: 0.9340\n",
            "Epoch 16/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.3244 - acc: 0.9056 - val_loss: 0.2180 - val_acc: 0.9352\n",
            "Epoch 17/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.3141 - acc: 0.9086 - val_loss: 0.2122 - val_acc: 0.9377\n",
            "Epoch 18/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.3102 - acc: 0.9095 - val_loss: 0.2076 - val_acc: 0.9390\n",
            "Epoch 19/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.3018 - acc: 0.9119 - val_loss: 0.2018 - val_acc: 0.9409\n",
            "Epoch 20/250\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.2931 - acc: 0.9131 - val_loss: 0.1974 - val_acc: 0.9420\n",
            "Epoch 21/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.2866 - acc: 0.9171 - val_loss: 0.1920 - val_acc: 0.9438\n",
            "Epoch 22/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2789 - acc: 0.9172 - val_loss: 0.1879 - val_acc: 0.9447\n",
            "Epoch 23/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2730 - acc: 0.9200 - val_loss: 0.1842 - val_acc: 0.9464\n",
            "Epoch 24/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.2686 - acc: 0.9211 - val_loss: 0.1811 - val_acc: 0.9464\n",
            "Epoch 25/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2618 - acc: 0.9234 - val_loss: 0.1770 - val_acc: 0.9478\n",
            "Epoch 26/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2584 - acc: 0.9249 - val_loss: 0.1736 - val_acc: 0.9488\n",
            "Epoch 27/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2539 - acc: 0.9254 - val_loss: 0.1707 - val_acc: 0.9497\n",
            "Epoch 28/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2453 - acc: 0.9277 - val_loss: 0.1677 - val_acc: 0.9502\n",
            "Epoch 29/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2427 - acc: 0.9275 - val_loss: 0.1641 - val_acc: 0.9518\n",
            "Epoch 30/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.2397 - acc: 0.9297 - val_loss: 0.1616 - val_acc: 0.9521\n",
            "Epoch 31/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2361 - acc: 0.9304 - val_loss: 0.1590 - val_acc: 0.9536\n",
            "Epoch 32/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.2320 - acc: 0.9306 - val_loss: 0.1568 - val_acc: 0.9546\n",
            "Epoch 33/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.2284 - acc: 0.9326 - val_loss: 0.1534 - val_acc: 0.9553\n",
            "Epoch 34/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2257 - acc: 0.9327 - val_loss: 0.1519 - val_acc: 0.9552\n",
            "Epoch 35/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.2214 - acc: 0.9355 - val_loss: 0.1502 - val_acc: 0.9556\n",
            "Epoch 36/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.2169 - acc: 0.9353 - val_loss: 0.1485 - val_acc: 0.9563\n",
            "Epoch 37/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2124 - acc: 0.9375 - val_loss: 0.1459 - val_acc: 0.9572\n",
            "Epoch 38/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.2122 - acc: 0.9372 - val_loss: 0.1432 - val_acc: 0.9579\n",
            "Epoch 39/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.2091 - acc: 0.9388 - val_loss: 0.1422 - val_acc: 0.9576\n",
            "Epoch 40/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.2042 - acc: 0.9392 - val_loss: 0.1411 - val_acc: 0.9582\n",
            "Epoch 41/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.2027 - acc: 0.9398 - val_loss: 0.1397 - val_acc: 0.9581\n",
            "Epoch 42/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1985 - acc: 0.9415 - val_loss: 0.1367 - val_acc: 0.9596\n",
            "Epoch 43/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.2003 - acc: 0.9409 - val_loss: 0.1350 - val_acc: 0.9606\n",
            "Epoch 44/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1953 - acc: 0.9420 - val_loss: 0.1337 - val_acc: 0.9606\n",
            "Epoch 45/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1920 - acc: 0.9432 - val_loss: 0.1332 - val_acc: 0.9600\n",
            "Epoch 46/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1901 - acc: 0.9444 - val_loss: 0.1317 - val_acc: 0.9614\n",
            "Epoch 47/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1876 - acc: 0.9449 - val_loss: 0.1300 - val_acc: 0.9611\n",
            "Epoch 48/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1867 - acc: 0.9443 - val_loss: 0.1301 - val_acc: 0.9617\n",
            "Epoch 49/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1865 - acc: 0.9453 - val_loss: 0.1283 - val_acc: 0.9614\n",
            "Epoch 50/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1803 - acc: 0.9461 - val_loss: 0.1268 - val_acc: 0.9621\n",
            "Epoch 51/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1823 - acc: 0.9466 - val_loss: 0.1255 - val_acc: 0.9633\n",
            "Epoch 52/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1794 - acc: 0.9459 - val_loss: 0.1245 - val_acc: 0.9633\n",
            "Epoch 53/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1753 - acc: 0.9479 - val_loss: 0.1234 - val_acc: 0.9634\n",
            "Epoch 54/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1739 - acc: 0.9479 - val_loss: 0.1221 - val_acc: 0.9637\n",
            "Epoch 55/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1736 - acc: 0.9492 - val_loss: 0.1209 - val_acc: 0.9646\n",
            "Epoch 56/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1720 - acc: 0.9487 - val_loss: 0.1208 - val_acc: 0.9637\n",
            "Epoch 57/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1692 - acc: 0.9502 - val_loss: 0.1189 - val_acc: 0.9648\n",
            "Epoch 58/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1664 - acc: 0.9506 - val_loss: 0.1188 - val_acc: 0.9650\n",
            "Epoch 59/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1682 - acc: 0.9500 - val_loss: 0.1173 - val_acc: 0.9652\n",
            "Epoch 60/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1647 - acc: 0.9514 - val_loss: 0.1166 - val_acc: 0.9652\n",
            "Epoch 61/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1615 - acc: 0.9521 - val_loss: 0.1157 - val_acc: 0.9654\n",
            "Epoch 62/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1592 - acc: 0.9526 - val_loss: 0.1150 - val_acc: 0.9656\n",
            "Epoch 63/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1587 - acc: 0.9534 - val_loss: 0.1142 - val_acc: 0.9658\n",
            "Epoch 64/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1564 - acc: 0.9530 - val_loss: 0.1126 - val_acc: 0.9667\n",
            "Epoch 65/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1560 - acc: 0.9539 - val_loss: 0.1129 - val_acc: 0.9667\n",
            "Epoch 66/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1572 - acc: 0.9536 - val_loss: 0.1120 - val_acc: 0.9662\n",
            "Epoch 67/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1553 - acc: 0.9547 - val_loss: 0.1106 - val_acc: 0.9668\n",
            "Epoch 68/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1525 - acc: 0.9544 - val_loss: 0.1103 - val_acc: 0.9672\n",
            "Epoch 69/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1523 - acc: 0.9553 - val_loss: 0.1089 - val_acc: 0.9677\n",
            "Epoch 70/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1502 - acc: 0.9551 - val_loss: 0.1086 - val_acc: 0.9680\n",
            "Epoch 71/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1478 - acc: 0.9566 - val_loss: 0.1082 - val_acc: 0.9680\n",
            "Epoch 72/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1450 - acc: 0.9565 - val_loss: 0.1073 - val_acc: 0.9685\n",
            "Epoch 73/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1462 - acc: 0.9569 - val_loss: 0.1069 - val_acc: 0.9680\n",
            "Epoch 74/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1439 - acc: 0.9583 - val_loss: 0.1068 - val_acc: 0.9684\n",
            "Epoch 75/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1447 - acc: 0.9566 - val_loss: 0.1059 - val_acc: 0.9680\n",
            "Epoch 76/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1414 - acc: 0.9580 - val_loss: 0.1060 - val_acc: 0.9685\n",
            "Epoch 77/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1421 - acc: 0.9579 - val_loss: 0.1056 - val_acc: 0.9679\n",
            "Epoch 78/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1399 - acc: 0.9589 - val_loss: 0.1044 - val_acc: 0.9689\n",
            "Epoch 79/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1415 - acc: 0.9573 - val_loss: 0.1042 - val_acc: 0.9687\n",
            "Epoch 80/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1393 - acc: 0.9595 - val_loss: 0.1034 - val_acc: 0.9689\n",
            "Epoch 81/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1370 - acc: 0.9590 - val_loss: 0.1035 - val_acc: 0.9687\n",
            "Epoch 82/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1365 - acc: 0.9579 - val_loss: 0.1031 - val_acc: 0.9690\n",
            "Epoch 83/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1344 - acc: 0.9597 - val_loss: 0.1020 - val_acc: 0.9695\n",
            "Epoch 84/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1338 - acc: 0.9599 - val_loss: 0.1015 - val_acc: 0.9692\n",
            "Epoch 85/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1337 - acc: 0.9604 - val_loss: 0.1015 - val_acc: 0.9696\n",
            "Epoch 86/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1346 - acc: 0.9602 - val_loss: 0.1006 - val_acc: 0.9699\n",
            "Epoch 87/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1304 - acc: 0.9609 - val_loss: 0.1004 - val_acc: 0.9703\n",
            "Epoch 88/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1321 - acc: 0.9594 - val_loss: 0.1000 - val_acc: 0.9697\n",
            "Epoch 89/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1304 - acc: 0.9608 - val_loss: 0.0991 - val_acc: 0.9702\n",
            "Epoch 90/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1321 - acc: 0.9604 - val_loss: 0.0987 - val_acc: 0.9703\n",
            "Epoch 91/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1286 - acc: 0.9620 - val_loss: 0.0982 - val_acc: 0.9709\n",
            "Epoch 92/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1318 - acc: 0.9600 - val_loss: 0.0986 - val_acc: 0.9715\n",
            "Epoch 93/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1285 - acc: 0.9616 - val_loss: 0.0977 - val_acc: 0.9708\n",
            "Epoch 94/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1249 - acc: 0.9621 - val_loss: 0.0975 - val_acc: 0.9712\n",
            "Epoch 95/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1265 - acc: 0.9626 - val_loss: 0.0974 - val_acc: 0.9712\n",
            "Epoch 96/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1239 - acc: 0.9625 - val_loss: 0.0969 - val_acc: 0.9715\n",
            "Epoch 97/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1241 - acc: 0.9621 - val_loss: 0.0960 - val_acc: 0.9715\n",
            "Epoch 98/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1235 - acc: 0.9630 - val_loss: 0.0966 - val_acc: 0.9715\n",
            "Epoch 99/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1217 - acc: 0.9644 - val_loss: 0.0957 - val_acc: 0.9718\n",
            "Epoch 100/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1211 - acc: 0.9636 - val_loss: 0.0957 - val_acc: 0.9722\n",
            "Epoch 101/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1227 - acc: 0.9632 - val_loss: 0.0961 - val_acc: 0.9725\n",
            "Epoch 102/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1215 - acc: 0.9642 - val_loss: 0.0947 - val_acc: 0.9722\n",
            "Epoch 103/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1192 - acc: 0.9646 - val_loss: 0.0950 - val_acc: 0.9719\n",
            "Epoch 104/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1177 - acc: 0.9647 - val_loss: 0.0942 - val_acc: 0.9721\n",
            "Epoch 105/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1164 - acc: 0.9655 - val_loss: 0.0943 - val_acc: 0.9728\n",
            "Epoch 106/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1170 - acc: 0.9649 - val_loss: 0.0940 - val_acc: 0.9725\n",
            "Epoch 107/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1169 - acc: 0.9647 - val_loss: 0.0940 - val_acc: 0.9732\n",
            "Epoch 108/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1138 - acc: 0.9665 - val_loss: 0.0933 - val_acc: 0.9723\n",
            "Epoch 109/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1146 - acc: 0.9659 - val_loss: 0.0933 - val_acc: 0.9734\n",
            "Epoch 110/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1141 - acc: 0.9658 - val_loss: 0.0928 - val_acc: 0.9727\n",
            "Epoch 111/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1146 - acc: 0.9658 - val_loss: 0.0927 - val_acc: 0.9721\n",
            "Epoch 112/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1116 - acc: 0.9661 - val_loss: 0.0917 - val_acc: 0.9737\n",
            "Epoch 113/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1126 - acc: 0.9657 - val_loss: 0.0921 - val_acc: 0.9732\n",
            "Epoch 114/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1144 - acc: 0.9655 - val_loss: 0.0915 - val_acc: 0.9737\n",
            "Epoch 115/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1113 - acc: 0.9664 - val_loss: 0.0914 - val_acc: 0.9742\n",
            "Epoch 116/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1087 - acc: 0.9675 - val_loss: 0.0912 - val_acc: 0.9739\n",
            "Epoch 117/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1115 - acc: 0.9665 - val_loss: 0.0912 - val_acc: 0.9735\n",
            "Epoch 118/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1086 - acc: 0.9671 - val_loss: 0.0908 - val_acc: 0.9738\n",
            "Epoch 119/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1117 - acc: 0.9661 - val_loss: 0.0910 - val_acc: 0.9743\n",
            "Epoch 120/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1070 - acc: 0.9676 - val_loss: 0.0901 - val_acc: 0.9744\n",
            "Epoch 121/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1083 - acc: 0.9669 - val_loss: 0.0904 - val_acc: 0.9743\n",
            "Epoch 122/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1074 - acc: 0.9673 - val_loss: 0.0895 - val_acc: 0.9747\n",
            "Epoch 123/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1042 - acc: 0.9680 - val_loss: 0.0891 - val_acc: 0.9747\n",
            "Epoch 124/250\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.1046 - acc: 0.9684 - val_loss: 0.0894 - val_acc: 0.9744\n",
            "Epoch 125/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1043 - acc: 0.9691 - val_loss: 0.0892 - val_acc: 0.9744\n",
            "Epoch 126/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1035 - acc: 0.9685 - val_loss: 0.0889 - val_acc: 0.9746\n",
            "Epoch 127/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1033 - acc: 0.9685 - val_loss: 0.0890 - val_acc: 0.9747\n",
            "Epoch 128/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1042 - acc: 0.9688 - val_loss: 0.0884 - val_acc: 0.9751\n",
            "Epoch 129/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1050 - acc: 0.9678 - val_loss: 0.0883 - val_acc: 0.9751\n",
            "Epoch 130/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1039 - acc: 0.9691 - val_loss: 0.0883 - val_acc: 0.9750\n",
            "Epoch 131/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1025 - acc: 0.9688 - val_loss: 0.0876 - val_acc: 0.9752\n",
            "Epoch 132/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0999 - acc: 0.9702 - val_loss: 0.0879 - val_acc: 0.9750\n",
            "Epoch 133/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1009 - acc: 0.9687 - val_loss: 0.0876 - val_acc: 0.9752\n",
            "Epoch 134/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0989 - acc: 0.9687 - val_loss: 0.0877 - val_acc: 0.9748\n",
            "Epoch 135/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1007 - acc: 0.9694 - val_loss: 0.0880 - val_acc: 0.9748\n",
            "Epoch 136/250\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.1001 - acc: 0.9704 - val_loss: 0.0876 - val_acc: 0.9752\n",
            "Epoch 137/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0996 - acc: 0.9695 - val_loss: 0.0878 - val_acc: 0.9756\n",
            "Epoch 138/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1003 - acc: 0.9691 - val_loss: 0.0875 - val_acc: 0.9756\n",
            "Epoch 139/250\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.0975 - acc: 0.9706 - val_loss: 0.0873 - val_acc: 0.9753\n",
            "Epoch 140/250\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.0964 - acc: 0.9707 - val_loss: 0.0869 - val_acc: 0.9758\n",
            "Epoch 141/250\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.0971 - acc: 0.9698 - val_loss: 0.0867 - val_acc: 0.9759\n",
            "Epoch 142/250\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 0.0952 - acc: 0.9708 - val_loss: 0.0865 - val_acc: 0.9762\n",
            "Epoch 143/250\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 0.0969 - acc: 0.9702 - val_loss: 0.0868 - val_acc: 0.9762\n",
            "Epoch 144/250\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.0945 - acc: 0.9712 - val_loss: 0.0865 - val_acc: 0.9757\n",
            "Epoch 145/250\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.0961 - acc: 0.9707 - val_loss: 0.0859 - val_acc: 0.9757\n",
            "Epoch 146/250\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.0939 - acc: 0.9721 - val_loss: 0.0863 - val_acc: 0.9755\n",
            "Epoch 147/250\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.0936 - acc: 0.9715 - val_loss: 0.0866 - val_acc: 0.9759\n",
            "Epoch 148/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0948 - acc: 0.9709 - val_loss: 0.0861 - val_acc: 0.9759\n",
            "Epoch 149/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0925 - acc: 0.9721 - val_loss: 0.0856 - val_acc: 0.9758\n",
            "Epoch 150/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0916 - acc: 0.9721 - val_loss: 0.0862 - val_acc: 0.9759\n",
            "Epoch 151/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0941 - acc: 0.9718 - val_loss: 0.0856 - val_acc: 0.9761\n",
            "Epoch 152/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0923 - acc: 0.9725 - val_loss: 0.0853 - val_acc: 0.9763\n",
            "Epoch 153/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0892 - acc: 0.9727 - val_loss: 0.0852 - val_acc: 0.9761\n",
            "Epoch 154/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0916 - acc: 0.9724 - val_loss: 0.0854 - val_acc: 0.9761\n",
            "Epoch 155/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0909 - acc: 0.9726 - val_loss: 0.0850 - val_acc: 0.9762\n",
            "Epoch 156/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0910 - acc: 0.9728 - val_loss: 0.0849 - val_acc: 0.9757\n",
            "Epoch 157/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0900 - acc: 0.9732 - val_loss: 0.0850 - val_acc: 0.9757\n",
            "Epoch 158/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0885 - acc: 0.9730 - val_loss: 0.0854 - val_acc: 0.9762\n",
            "Epoch 159/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0877 - acc: 0.9727 - val_loss: 0.0845 - val_acc: 0.9766\n",
            "Epoch 160/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0893 - acc: 0.9729 - val_loss: 0.0848 - val_acc: 0.9763\n",
            "Epoch 161/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0887 - acc: 0.9728 - val_loss: 0.0841 - val_acc: 0.9767\n",
            "Epoch 162/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0884 - acc: 0.9734 - val_loss: 0.0843 - val_acc: 0.9764\n",
            "Epoch 163/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0869 - acc: 0.9735 - val_loss: 0.0846 - val_acc: 0.9762\n",
            "Epoch 164/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0877 - acc: 0.9730 - val_loss: 0.0841 - val_acc: 0.9769\n",
            "Epoch 165/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0859 - acc: 0.9735 - val_loss: 0.0840 - val_acc: 0.9762\n",
            "Epoch 166/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0862 - acc: 0.9733 - val_loss: 0.0848 - val_acc: 0.9762\n",
            "Epoch 167/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0857 - acc: 0.9738 - val_loss: 0.0847 - val_acc: 0.9761\n",
            "Epoch 168/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0837 - acc: 0.9747 - val_loss: 0.0843 - val_acc: 0.9758\n",
            "Epoch 169/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0853 - acc: 0.9740 - val_loss: 0.0839 - val_acc: 0.9759\n",
            "Epoch 170/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0871 - acc: 0.9735 - val_loss: 0.0834 - val_acc: 0.9763\n",
            "Epoch 171/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0854 - acc: 0.9736 - val_loss: 0.0832 - val_acc: 0.9765\n",
            "Epoch 172/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0845 - acc: 0.9738 - val_loss: 0.0833 - val_acc: 0.9761\n",
            "Epoch 173/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0858 - acc: 0.9739 - val_loss: 0.0840 - val_acc: 0.9762\n",
            "Epoch 174/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0826 - acc: 0.9748 - val_loss: 0.0833 - val_acc: 0.9762\n",
            "Epoch 175/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0856 - acc: 0.9733 - val_loss: 0.0836 - val_acc: 0.9765\n",
            "Epoch 176/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0807 - acc: 0.9753 - val_loss: 0.0838 - val_acc: 0.9767\n",
            "Epoch 177/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0823 - acc: 0.9751 - val_loss: 0.0828 - val_acc: 0.9770\n",
            "Epoch 178/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0825 - acc: 0.9747 - val_loss: 0.0828 - val_acc: 0.9770\n",
            "Epoch 179/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0812 - acc: 0.9752 - val_loss: 0.0822 - val_acc: 0.9766\n",
            "Epoch 180/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0834 - acc: 0.9739 - val_loss: 0.0831 - val_acc: 0.9769\n",
            "Epoch 181/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0811 - acc: 0.9748 - val_loss: 0.0819 - val_acc: 0.9769\n",
            "Epoch 182/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0784 - acc: 0.9756 - val_loss: 0.0827 - val_acc: 0.9768\n",
            "Epoch 183/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0802 - acc: 0.9759 - val_loss: 0.0825 - val_acc: 0.9769\n",
            "Epoch 184/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0808 - acc: 0.9750 - val_loss: 0.0818 - val_acc: 0.9767\n",
            "Epoch 185/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0792 - acc: 0.9753 - val_loss: 0.0822 - val_acc: 0.9762\n",
            "Epoch 186/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0806 - acc: 0.9756 - val_loss: 0.0825 - val_acc: 0.9767\n",
            "Epoch 187/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0785 - acc: 0.9756 - val_loss: 0.0821 - val_acc: 0.9762\n",
            "Epoch 188/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0795 - acc: 0.9754 - val_loss: 0.0813 - val_acc: 0.9766\n",
            "Epoch 189/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0775 - acc: 0.9758 - val_loss: 0.0821 - val_acc: 0.9768\n",
            "Epoch 190/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0775 - acc: 0.9758 - val_loss: 0.0822 - val_acc: 0.9764\n",
            "Epoch 191/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0780 - acc: 0.9767 - val_loss: 0.0823 - val_acc: 0.9763\n",
            "Epoch 192/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0821 - val_acc: 0.9770\n",
            "Epoch 193/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0775 - acc: 0.9761 - val_loss: 0.0818 - val_acc: 0.9770\n",
            "Epoch 194/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0780 - acc: 0.9761 - val_loss: 0.0819 - val_acc: 0.9770\n",
            "Epoch 195/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0768 - acc: 0.9764 - val_loss: 0.0820 - val_acc: 0.9767\n",
            "Epoch 196/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0741 - acc: 0.9770 - val_loss: 0.0818 - val_acc: 0.9766\n",
            "Epoch 197/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0769 - acc: 0.9756 - val_loss: 0.0816 - val_acc: 0.9767\n",
            "Epoch 198/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0749 - acc: 0.9767 - val_loss: 0.0814 - val_acc: 0.9770\n",
            "Epoch 199/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0750 - acc: 0.9771 - val_loss: 0.0811 - val_acc: 0.9769\n",
            "Epoch 200/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0742 - acc: 0.9768 - val_loss: 0.0810 - val_acc: 0.9764\n",
            "Epoch 201/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0746 - acc: 0.9765 - val_loss: 0.0815 - val_acc: 0.9767\n",
            "Epoch 202/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0781 - acc: 0.9762 - val_loss: 0.0811 - val_acc: 0.9771\n",
            "Epoch 203/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0748 - acc: 0.9772 - val_loss: 0.0810 - val_acc: 0.9770\n",
            "Epoch 204/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0719 - acc: 0.9773 - val_loss: 0.0811 - val_acc: 0.9767\n",
            "Epoch 205/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0752 - acc: 0.9767 - val_loss: 0.0813 - val_acc: 0.9772\n",
            "Epoch 206/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0730 - acc: 0.9773 - val_loss: 0.0813 - val_acc: 0.9771\n",
            "Epoch 207/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0724 - acc: 0.9774 - val_loss: 0.0811 - val_acc: 0.9764\n",
            "Epoch 208/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0725 - acc: 0.9770 - val_loss: 0.0814 - val_acc: 0.9771\n",
            "Epoch 209/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0732 - acc: 0.9775 - val_loss: 0.0813 - val_acc: 0.9769\n",
            "Epoch 210/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0710 - acc: 0.9780 - val_loss: 0.0816 - val_acc: 0.9768\n",
            "Epoch 211/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0734 - acc: 0.9764 - val_loss: 0.0819 - val_acc: 0.9770\n",
            "Epoch 212/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0739 - acc: 0.9770 - val_loss: 0.0815 - val_acc: 0.9767\n",
            "Epoch 213/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0724 - acc: 0.9779 - val_loss: 0.0809 - val_acc: 0.9776\n",
            "Epoch 214/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0722 - acc: 0.9780 - val_loss: 0.0811 - val_acc: 0.9773\n",
            "Epoch 215/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0706 - acc: 0.9786 - val_loss: 0.0809 - val_acc: 0.9772\n",
            "Epoch 216/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0707 - acc: 0.9776 - val_loss: 0.0809 - val_acc: 0.9772\n",
            "Epoch 217/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0707 - acc: 0.9783 - val_loss: 0.0806 - val_acc: 0.9776\n",
            "Epoch 218/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0686 - acc: 0.9786 - val_loss: 0.0810 - val_acc: 0.9771\n",
            "Epoch 219/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0707 - acc: 0.9781 - val_loss: 0.0802 - val_acc: 0.9768\n",
            "Epoch 220/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0689 - acc: 0.9790 - val_loss: 0.0803 - val_acc: 0.9770\n",
            "Epoch 221/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0705 - acc: 0.9780 - val_loss: 0.0811 - val_acc: 0.9768\n",
            "Epoch 222/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0687 - acc: 0.9787 - val_loss: 0.0808 - val_acc: 0.9769\n",
            "Epoch 223/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0707 - acc: 0.9773 - val_loss: 0.0807 - val_acc: 0.9772\n",
            "Epoch 224/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0699 - acc: 0.9790 - val_loss: 0.0804 - val_acc: 0.9770\n",
            "Epoch 225/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0674 - acc: 0.9791 - val_loss: 0.0806 - val_acc: 0.9774\n",
            "Epoch 226/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0684 - acc: 0.9789 - val_loss: 0.0805 - val_acc: 0.9772\n",
            "Epoch 227/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0668 - acc: 0.9792 - val_loss: 0.0807 - val_acc: 0.9772\n",
            "Epoch 228/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0693 - acc: 0.9788 - val_loss: 0.0807 - val_acc: 0.9770\n",
            "Epoch 229/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0687 - acc: 0.9784 - val_loss: 0.0806 - val_acc: 0.9772\n",
            "Epoch 230/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0685 - acc: 0.9783 - val_loss: 0.0802 - val_acc: 0.9768\n",
            "Epoch 231/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0671 - acc: 0.9794 - val_loss: 0.0800 - val_acc: 0.9774\n",
            "Epoch 232/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0681 - acc: 0.9786 - val_loss: 0.0802 - val_acc: 0.9772\n",
            "Epoch 233/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0647 - acc: 0.9797 - val_loss: 0.0806 - val_acc: 0.9774\n",
            "Epoch 234/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0679 - acc: 0.9782 - val_loss: 0.0803 - val_acc: 0.9777\n",
            "Epoch 235/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0664 - acc: 0.9793 - val_loss: 0.0795 - val_acc: 0.9775\n",
            "Epoch 236/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0686 - acc: 0.9786 - val_loss: 0.0795 - val_acc: 0.9776\n",
            "Epoch 237/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0650 - acc: 0.9795 - val_loss: 0.0802 - val_acc: 0.9776\n",
            "Epoch 238/250\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0665 - acc: 0.9794 - val_loss: 0.0805 - val_acc: 0.9774\n",
            "Epoch 239/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0668 - acc: 0.9794 - val_loss: 0.0807 - val_acc: 0.9777\n",
            "Epoch 240/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0687 - acc: 0.9788 - val_loss: 0.0804 - val_acc: 0.9777\n",
            "Epoch 241/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0648 - acc: 0.9799 - val_loss: 0.0806 - val_acc: 0.9775\n",
            "Epoch 242/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0657 - acc: 0.9790 - val_loss: 0.0798 - val_acc: 0.9777\n",
            "Epoch 243/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0658 - acc: 0.9792 - val_loss: 0.0796 - val_acc: 0.9777\n",
            "Epoch 244/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0655 - acc: 0.9797 - val_loss: 0.0798 - val_acc: 0.9776\n",
            "Epoch 245/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0634 - acc: 0.9804 - val_loss: 0.0799 - val_acc: 0.9774\n",
            "Epoch 246/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0628 - acc: 0.9802 - val_loss: 0.0810 - val_acc: 0.9770\n",
            "Epoch 247/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0621 - acc: 0.9801 - val_loss: 0.0802 - val_acc: 0.9777\n",
            "Epoch 248/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0632 - acc: 0.9805 - val_loss: 0.0803 - val_acc: 0.9771\n",
            "Epoch 249/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0636 - acc: 0.9801 - val_loss: 0.0804 - val_acc: 0.9779\n",
            "Epoch 250/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0617 - acc: 0.9808 - val_loss: 0.0801 - val_acc: 0.9778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kuaRbTadUdjP",
        "colab_type": "code",
        "outputId": "25f9d363-334d-47e5-f21f-fd77c8990e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 38us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MopZPjWLZOB5",
        "colab_type": "code",
        "outputId": "56951514-9471-4f4d-f410-403958a55aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Test score/loss :\", score[0])\n",
        "print(\"Test accuracy: \", score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score/loss : 0.07741551164172124\n",
            "Test accuracy:  0.9778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UbPDeJKHZnlN",
        "colab_type": "code",
        "outputId": "14037f80-d42d-4ee2-c80f-132d2dae9368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#list all data in history\n",
        "print(history.history.keys())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DxOFf3C0Zygh",
        "colab_type": "code",
        "outputId": "7136c488-186a-40d8-ca57-ce888dce1ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "#plot for accuracy \n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyFogyKMbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mTRuju0mifJl",
        "colab_type": "code",
        "outputId": "28c6386a-2bbc-48e5-9a3f-32d3d1b59bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "#plot for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LDH2_7InmP5O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8-oG626miIS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We got accuracy of 97.78% (in previous experiment we got 0.9461) and loss of 0.077415 (we got 0.9461 in previous experiment). \n",
        "so with dropout we can do more epocs and avoid overfitting which gives us a better model. "
      ]
    },
    {
      "metadata": {
        "id": "kitf9gWRoWwY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}