{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_keras_1.1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandvimal/deeplearning-experiments/blob/master/mnist_keras_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_T-vhMRe2HDk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Experiment 1.1 MNIST"
      ]
    },
    {
      "metadata": {
        "id": "sMmlPK0-XPNl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "this experiment is iteration from deep learning with keras book chapter 1\n",
        "\n",
        "In last model (mnist_keras_1.0) we used 200 epocs and few layers. This time we will try to use less epochs but bigger net (adding more layers dense+activation). so our neural net can learn more with less epochs."
      ]
    },
    {
      "metadata": {
        "id": "FvqN9TRL0cMi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import all libs needed\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "\n",
        "np.random.seed(1671) #this is so our random numbers are same to get same random weights and get similar results to original author. \n",
        "#removing above line can have slightly different results in accuracy and loss in the end but overall results will be similar."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSFu8FuM2bkG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NB_EPOCH = 20\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10\n",
        "OPTIMIZER = SGD()\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT=0.2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pmmRnQ3_3pfT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#shuffle and split data\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Aqy8d01d4qjN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RESHAPED = 784 #28*28=784\n",
        "\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zaALFekc4w4X",
        "colab_type": "code",
        "outputId": "f6b21ddc-855f-410c-bee9-dac4c4a1f4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#normalize\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aOIaPmiW6lqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#one hot encoding of labels\n",
        "Y_train = np_utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(Y_test, NB_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q71gb6g29acL",
        "colab_type": "code",
        "outputId": "5c8836f8-3cf7-4582-ccdc-290b33e78f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "cell_type": "code",
      "source": [
        "#model\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(NB_CLASSES))     #10 hidden layers because we have 10 classes to categorize.\n",
        "model.add(Activation('softmax'))  \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LRNJ8lgA-t2V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=OPTIMIZER,\n",
        "              metrics=['accuracy']\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3G73wVLByqW",
        "colab_type": "code",
        "outputId": "6b425ea1-b2f1-450d-ef46-263509c84ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, Y_train,\n",
        "                   batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 2s 47us/step - loss: 1.4830 - acc: 0.6231 - val_loss: 0.7584 - val_acc: 0.8286\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 3s 59us/step - loss: 0.6049 - acc: 0.8463 - val_loss: 0.4550 - val_acc: 0.8851\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 3s 60us/step - loss: 0.4398 - acc: 0.8801 - val_loss: 0.3710 - val_acc: 0.9019\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 3s 59us/step - loss: 0.3767 - acc: 0.8952 - val_loss: 0.3322 - val_acc: 0.9081\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 3s 60us/step - loss: 0.3415 - acc: 0.9025 - val_loss: 0.3055 - val_acc: 0.9147\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 3s 60us/step - loss: 0.3175 - acc: 0.9086 - val_loss: 0.2880 - val_acc: 0.9183\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 3s 59us/step - loss: 0.2990 - acc: 0.9136 - val_loss: 0.2727 - val_acc: 0.9224\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 3s 60us/step - loss: 0.2839 - acc: 0.9180 - val_loss: 0.2607 - val_acc: 0.9266\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 3s 58us/step - loss: 0.2714 - acc: 0.9217 - val_loss: 0.2505 - val_acc: 0.9297\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 3s 59us/step - loss: 0.2602 - acc: 0.9252 - val_loss: 0.2430 - val_acc: 0.9308\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 3s 58us/step - loss: 0.2502 - acc: 0.9285 - val_loss: 0.2341 - val_acc: 0.9334\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 3s 60us/step - loss: 0.2409 - acc: 0.9300 - val_loss: 0.2271 - val_acc: 0.9352\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 3s 60us/step - loss: 0.2326 - acc: 0.9333 - val_loss: 0.2227 - val_acc: 0.9365\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 3s 61us/step - loss: 0.2253 - acc: 0.9353 - val_loss: 0.2147 - val_acc: 0.9395\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 3s 62us/step - loss: 0.2182 - acc: 0.9374 - val_loss: 0.2083 - val_acc: 0.9410\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 3s 61us/step - loss: 0.2116 - acc: 0.9393 - val_loss: 0.2030 - val_acc: 0.9430\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 3s 60us/step - loss: 0.2055 - acc: 0.9413 - val_loss: 0.1981 - val_acc: 0.9445\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 3s 60us/step - loss: 0.1996 - acc: 0.9429 - val_loss: 0.1932 - val_acc: 0.9459\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 3s 60us/step - loss: 0.1942 - acc: 0.9432 - val_loss: 0.1894 - val_acc: 0.9468\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 3s 60us/step - loss: 0.1891 - acc: 0.9455 - val_loss: 0.1850 - val_acc: 0.9498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fVCV3RRHCLbM",
        "colab_type": "code",
        "outputId": "09b1c1b0-f1d3-4394-d35e-304f700a4e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 56us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GGW-XjsCCmj6",
        "colab_type": "code",
        "outputId": "0d5b9e7e-2d6b-4a8e-bb27-6cace32edf88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"test score/loss:\", score[0])\n",
        "print(\"test accuracy:\", score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test score/loss: 0.1860255774706602\n",
            "test accuracy: 0.9461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jkupYVpVCuHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sjCv-WIYCyPf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "by comparing to previous attempt (mnist_keras_1.0) to current one: \n",
        "\n",
        "*   our accuracy increased from 92.27% to 94.61%\n",
        "*   and loss decreased from 0.2773858511567116 to 0.1860\n",
        "\n",
        "by making the neural net denser (more dense+activation layer) our model performed better even with less no of epochs."
      ]
    }
  ]
}